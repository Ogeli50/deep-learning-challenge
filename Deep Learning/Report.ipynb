{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Description\n",
    "The dataset consists of more than 34,000 records of organizations that have previously applied for funding from Alphabet Soup. Each record includes the following columns:\n",
    "EIN: Identification number of the organization.\n",
    "NAME: Name of the organization.\n",
    "APPLICATION_TYPE: Type of application submitted to Alphabet Soup.\n",
    "AFFILIATION: Sector or industry affiliation of the organization.\n",
    "CLASSIFICATION: Government classification of the organization.\n",
    "USE_CASE: Intended use for the requested funding.\n",
    "ORGANIZATION: Type of organization.\n",
    "STATUS: Active status of the organization.\n",
    "INCOME_AMT: Income classification of the organization.\n",
    "SPECIAL_CONSIDERATIONS: Any special considerations for the application.\n",
    "ASK_AMT: Amount of funding requested.\n",
    "IS_SUCCESSFUL: Target variable indicating if the funding was used effectively (1 for successful, 0 for not successful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "Data Loading and Initial Inspection:\n",
    "The dataset was loaded into a Pandas Data Frame for exploration and initial analysis. Initial inspection included viewing the first few rows and summary statistics to understand the structure and content of the data.\n",
    "What variable(s) are your model's target(s)? The target variable for the model is IS_SUCCESSFUL.\n",
    "What are the feature variable(s) for your model? After dropping the identification columns (EIN and NAME), the feature variables include all other columns.\n",
    "Which variable(s) should be removed from the input data because they are neither targets nor features? EIN and NAME should be removed as they are identification columns and do not contribute to the prediction of success.\n",
    "Splitting Data:\n",
    "The dataset was split into feature variables (X) and the target (y). The target variable is IS_SUCCESSFUL, and feature variables include all other columns. The data was divided into training and testing sets using train_test_split to ensure effective model training and evaluation.\n",
    "Feature Scaling:\n",
    "The feature values were standardized using Standard Scaler to ensure that all features contributed equally to the model training, improving the neural network's convergence and performance.\n",
    "Compiling, Training, and Evaluating the Model\n",
    "How many neurons, layers, and activation functions did you select for your neural network model, and why? I selected 4 neurons for the first hidden layer, 13 neurons for the second hidden layer, and 22 neurons for the third hidden layer. ReLU was used as the activation function for the hidden layers to introduce non-linearity and improve learning efficiency. These configurations balance model complexity and learning capability while preventing overfitting and ensuring adequate training.\n",
    "Were you able to achieve the target model performance? The optimization strategies, such as adjusting the number of neurons, layers, and epochs, effectively improved the model's performance.\n",
    "What steps did you take in your attempts to increase model performance? \n",
    "To increase the model's performance, I took the following steps:\n",
    "- Utilized Data Cleaning by removing only the EIN column and retaining the NAME column for further differentiation between organizations.\n",
    "- Experimented with different numbers of neurons in hidden layers to balance model complexity and performance: \n",
    "    - First Hidden Layer: 4 neurons\n",
    "    - Second Hidden Layer: 13 neurons\n",
    "    - Third Hidden Layer: 22 neurons\n",
    "- Used ReLU activation for hidden layers to introduce non-linearity and improve learning capabilities.\n",
    "- Extended the training duration to 100 epochs to ensure the model had sufficient time to learn and converge.\n",
    "- Evaluated the model's performance using test data to assess accuracy and loss.\n",
    "- Adjusted the number of neurons, layers, and epochs based on performance metrics to achieve optimal results.\n",
    "- Applied StandardScaler to normalize feature values, ensuring the model training process was stable and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning model has achieved an accuracy of 78.04% after 100 epochs and a loss of 0.473, surpassing the target accuracy of 75%. This success indicates that the model effectively predicts whether an applicant will succeed if funded by Alphabet Soup. The model's architecture, with its multiple hidden layers and the use of ReLU activation functions, has been instrumental in this achievement. While the deep learning model has performed well, there is always room for improvement. Exploring alternative models, like the Random Forest Classifier, could offer additional insights and potentially enhance prediction performance. This approach allows for a comprehensive exploration of model options and a deeper understanding of the best techniques to solve the classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
